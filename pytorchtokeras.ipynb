{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorchtokeras.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1wDNbEl1-6eZDenEsleV9hRFbcnSnRV5Y","authorship_tag":"ABX9TyPZr1P7vEYiHsVmqDdws+ok"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"YUi8p37mms3N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606402290970,"user_tz":-540,"elapsed":1348,"user":{"displayName":"YOUNGJUN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXCkWtQqB5QSnRGkfHgYDCc_Ns7ntw7e80pQz6=s64","userId":"06692878673537715026"}},"outputId":"b4743222-c7d2-42cd-f1b9-13fe6590586e"},"source":["import torch\n","from torch.autograd import Variable as V\n","import torchvision.models as models\n","from torchvision import transforms as trn\n","from torch.nn import functional as F\n","import os\n","from PIL import Image\n","\n","# th architecture to use\n","arch = 'resnet50'\n","\n","# load the pre-trained weights\n","model_file = '%s_places365.pth.tar' % arch\n","if not os.access(model_file, os.W_OK):\n","    weight_url = 'http://places2.csail.mit.edu/models_places365/' + model_file\n","    os.system('wget ' + weight_url)\n","\n","model = models.__dict__[arch](num_classes=365)\n","checkpoint = torch.load(model_file, map_location=lambda storage, loc: storage)\n","state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\n","model.load_state_dict(state_dict)\n","model.eval()\n","\n"],"execution_count":120,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=2048, out_features=365, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":120}]},{"cell_type":"code","metadata":{"id":"N8MIyOqP1plW"},"source":["\n"," \n"," \n","def conv1_layer(x):    \n","    x = ZeroPadding2D(padding=(3, 3),name='conv1_pad')(x)\n","    x = Conv2D(64, (7, 7), strides=(2, 2),name='conv1')(x)\n","    x = BatchNormalization(name='bn1')(x)\n","    x = Activation('relu',name='conv1_relu')(x)\n","    x = ZeroPadding2D(padding=(1,1),name='pool1_pad')(x)\n"," \n","    return x   \n"," \n","    \n"," \n","def conv2_layer(x):         \n","    x = MaxPooling2D((3, 3), 2, name='pool1_pool')(x)     \n"," \n","    shortcut = x\n"," \n","    for i in range(3):\n","        if (i == 0):\n","            x = Conv2D(64, (1, 1), strides=(1, 1), padding='valid',name='layer1.0.conv1')(x)\n","            x = BatchNormalization(name='layer1.0.bn1')(x)\n","            x = Activation('relu',name='conv2_block0_1_relu')(x)\n","            \n","            x = Conv2D(64, (3, 3), strides=(1, 1), padding='same',name='layer1.0.conv2')(x)\n","            x = BatchNormalization(name='layer1.0.bn2')(x)\n","            x = Activation('relu',name='conv2_block0_2_relu')(x)\n"," \n","            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid',name='layer1.0.conv3')(x)\n","            shortcut = Conv2D(256, (1, 1), strides=(1, 1), padding='valid',name='layer1.0.downsample.0')(shortcut)            \n","            x = BatchNormalization(name='layer1.0.bn3')(x)\n","            shortcut = BatchNormalization(name='layer1.0.downsample.1')(shortcut)\n"," \n","            x = Add(name='conv2_block0_add')([x, shortcut])  \n","            x = Activation('relu',name='conv2_block0_out')(x)\n","            \n","            shortcut = x\n"," \n","        else:\n","            x = Conv2D(64, (1, 1), strides=(1, 1), padding='valid',name='layer1.' + str(i) +'.conv1')(x)\n","            x = BatchNormalization(name='layer1.' + str(i) +'.bn1')(x)\n","            x = Activation('relu',name='conv2_block' + str(i) +'_1_relu')(x)\n","            \n","            x = Conv2D(64, (3, 3), strides=(1, 1), padding='same',name='layer1.' + str(i) +'.conv2')(x)\n","            x = BatchNormalization(name='layer1.' + str(i) +'.bn2')(x)\n","            x = Activation('relu',name='conv2_block' + str(i) +'_2_relu')(x)\n"," \n","            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid',name='layer1.' + str(i) +'.conv3')(x)\n","            x = BatchNormalization(name='layer1.' + str(i) +'.bn3')(x)\n"," \n","            x = Add(name='conv2_block' + str(i) + '_add')([x, shortcut])\n","            x = Activation('relu',name='conv2_block' + str(i) +'_out')   (x)  \n"," \n","            shortcut = x        \n","    \n","    return x\n"," \n"," \n","def conv3_layer(x):         \n"," \n","    shortcut = x\n"," \n","    for i in range(4):\n","        if (i == 0):\n","            x = Conv2D(128, (1, 1), strides=(2, 2), padding='valid',name='layer2.0.conv1')(x)\n","            x = BatchNormalization(name='layer2.0.bn1')(x)\n","            x = Activation('relu',name='conv3_block0_1_relu')(x)\n","            \n","            x = Conv2D(128, (3, 3), strides=(1, 1), padding='same',name='layer2.0.conv2')(x)\n","            x = BatchNormalization(name='layer2.0.bn2')(x)\n","            x = Activation('relu',name='conv3_block0_2_relu')(x)\n"," \n","            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid',name='layer2.0.conv3')(x)\n","            shortcut = Conv2D(512, (1, 1), strides=(2, 2), padding='valid',name='layer2.0.downsample.0')(shortcut)            \n","            x = BatchNormalization(name='layer2.0.bn3')(x)\n","            shortcut = BatchNormalization(name='layer2.0.downsample.1')(shortcut)\n"," \n","            x = Add(name='conv3_block0_add')([x, shortcut])  \n","            x = Activation('relu',name='conv3_block0_out')(x)\n","            \n","            shortcut = x\n"," \n","        else:\n","            x = Conv2D(128, (1, 1), strides=(1, 1), padding='valid',name='layer2.' + str(i) +'.conv1')(x)\n","            x = BatchNormalization(name='layer2.' + str(i) +'.bn1')(x)\n","            x = Activation('relu',name='conv3_block' + str(i) +'_1_relu')(x)\n","            \n","            x = Conv2D(128, (3, 3), strides=(1, 1), padding='same',name='layer2.' + str(i) +'.conv2')(x)\n","            x = BatchNormalization(name='layer2.' + str(i) +'.bn2')(x)\n","            x = Activation('relu',name='conv3_block' + str(i) +'_2_relu')(x)\n"," \n","            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid',name='layer2.' + str(i) +'.conv3')(x)\n","            x = BatchNormalization(name='layer2.' + str(i) +'.bn3')(x)\n"," \n","            x = Add(name='conv3_block' + str(i) + '_add')([x, shortcut])\n","            x = Activation('relu',name='conv3_block' + str(i) +'_out')   (x)  \n"," \n","            shortcut = x        \n","    \n","    return x\n"," \n","\n","def conv4_layer(x):         \n"," \n","    shortcut = x\n"," \n","    for i in range(6):\n","        if (i == 0):\n","            x = Conv2D(256, (1, 1), strides=(2, 2), padding='valid',name='layer3.0.conv1')(x)\n","            x = BatchNormalization(name='layer3.0.bn1')(x)\n","            x = Activation('relu',name='conv4_block0_1_relu')(x)\n","            \n","            x = Conv2D(256, (3, 3), strides=(1, 1), padding='same',name='layer3.0.conv2')(x)\n","            x = BatchNormalization(name='layer3.0.bn2')(x)\n","            x = Activation('relu',name='conv4_block0_2_relu')(x)\n"," \n","            x = Conv2D(1024, (1, 1), strides=(1, 1), padding='valid',name='layer3.0.conv3')(x)\n","            shortcut = Conv2D(1024, (1, 1), strides=(2, 2), padding='valid',name='layer3.0.downsample.0')(shortcut)            \n","            x = BatchNormalization(name='layer3.0.bn3')(x)\n","            shortcut = BatchNormalization(name='layer3.0.downsample.1')(shortcut)\n"," \n","            x = Add(name='conv4_block0_add')([x, shortcut])  \n","            x = Activation('relu',name='conv4_block0_out')(x)\n","            \n","            shortcut = x\n"," \n","        else:\n","            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid',name='layer3.' + str(i) +'.conv1')(x)\n","            x = BatchNormalization(name='layer3.' + str(i) +'.bn1')(x)\n","            x = Activation('relu',name='conv4_block' + str(i) +'_1_relu')(x)\n","            \n","            x = Conv2D(256, (3, 3), strides=(1, 1), padding='same',name='layer3.' + str(i) +'.conv2')(x)\n","            x = BatchNormalization(name='layer3.' + str(i) +'.bn2')(x)\n","            x = Activation('relu',name='conv4_block' + str(i) +'_2_relu')(x)\n"," \n","            x = Conv2D(1024, (1, 1), strides=(1, 1), padding='valid',name='layer3.' + str(i) +'.conv3')(x)\n","            x = BatchNormalization(name='layer3.' + str(i) +'.bn3')(x)\n"," \n","            x = Add(name='conv4_block' + str(i) + '_add')([x, shortcut])\n","            x = Activation('relu',name='conv4_block' + str(i) +'_out')   (x)  \n"," \n","            shortcut = x        \n","    \n","    return x\n"," \n"," \n","\n","\n","def conv5_layer(x):         \n","\n","    shortcut = x\n"," \n","    for i in range(3):\n","        if (i == 0):\n","            x = Conv2D(512, (1, 1), strides=(2, 2), padding='valid',name='layer4.0.conv1')(x)\n","            x = BatchNormalization(name='layer4.0.bn1')(x)\n","            x = Activation('relu',name='conv5_block0_1_relu')(x)\n","            \n","            x = Conv2D(512, (3, 3), strides=(1, 1), padding='same',name='layer4.0.conv2')(x)\n","            x = BatchNormalization(name='layer4.0.bn2')(x)\n","            x = Activation('relu',name='conv5_block0_2_relu')(x)\n"," \n","            x = Conv2D(2048, (1, 1), strides=(1, 1), padding='valid',name='layer4.0.conv3')(x)\n","            shortcut = Conv2D(2048, (1, 1), strides=(2, 2), padding='valid',name='layer4.0.downsample.0')(shortcut)            \n","            x = BatchNormalization(name='layer4.0.bn3')(x)\n","            shortcut = BatchNormalization(name='layer4.0.downsample.1')(shortcut)\n"," \n","            x = Add(name='conv5_block0_add')([x, shortcut])  \n","            x = Activation('relu',name='conv5_block0_out')(x)\n","            \n","            shortcut = x\n"," \n","        else:\n","            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid',name='layer4.' + str(i) +'.conv1')(x)\n","            x = BatchNormalization(name='layer4.' + str(i) +'.bn1')(x)\n","            x = Activation('relu',name='conv5_block' + str(i) +'_1_relu')(x)\n","            \n","            x = Conv2D(512, (3, 3), strides=(1, 1), padding='same',name='layer4.' + str(i) +'.conv2')(x)\n","            x = BatchNormalization(name='layer4.' + str(i) +'.bn2')(x)\n","            x = Activation('relu',name='conv5_block' + str(i) +'_2_relu')(x)\n"," \n","            x = Conv2D(2048, (1, 1), strides=(1, 1), padding='valid',name='layer4.' + str(i) +'.conv3')(x)\n","            x = BatchNormalization(name='layer4.' + str(i) +'.bn3')(x)\n"," \n","            x = Add(name='conv5_block' + str(i) + '_add')([x, shortcut])\n","            x = Activation('relu',name='conv5_block' + str(i) +'_out')   (x)  \n"," \n","            shortcut = x        \n","    \n","    return x\n"," \n"," \n"," \n","input_tensor = Input(shape=(224, 224, 3), dtype='float32', name='input')\n","x = conv1_layer(input_tensor)\n","x = conv2_layer(x)\n","x = conv3_layer(x)\n","x = conv4_layer(x)\n","x = conv5_layer(x)\n","\n","#output_tensor = GlobalAveragePooling2D()(x)\n","x = GlobalAveragePooling2D()(x)\n","output_tensor = Dense(365, activation='softmax', name='fc')(x)\n"," \n","resnet50 = Model(input_tensor, output_tensor)\n","resnet50.summary()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9XvS6T9z00sf"},"source":["def pth2keras(pth_model, keras_model):\n","    m = {}\n","\n","    for k, v in pth_model.named_parameters():\n","        m[k] = v\n","    for k, v in pth_model.named_buffers(): # for batchnormalization\n","        m[k] = v\n","    print(m.keys())\n","    with torch.no_grad():\n","        for layer in keras_model.layers:\n","            if isinstance(layer, DepthwiseConv2D):\n","                print(layer.name)\n","                weights = []\n","                weights.append(m[layer.name+'.weight'].permute(2, 3, 0, 1).data.numpy()) \n","                if layer.use_bias:\n","                  if layer.name+'.bias' in m:\n","                      weights.append(m[layer.name+'.bias'].data.numpy()) # bias\n","                  else:\n","                      weights.append(layer.weights[1].numpy())\n","\n","                layer.set_weights(weights)\n","            elif isinstance(layer, Conv2D):\n","                print(layer.name)\n","                weights = []\n","                weights.append(m[layer.name+'.weight'].permute(2, 3, 1, 0).data.numpy()) # weight\n","                if layer.use_bias:\n","                  if layer.name+'.bias' in m:\n","                      weights.append(m[layer.name+'.bias'].data.numpy()) # bias\n","                  else:\n","                      weights.append(layer.weights[1].numpy())\n","\n","                layer.set_weights(weights)\n","            elif isinstance(layer, BatchNormalization):\n","                print(layer.name)\n","                weights = []\n","                if layer.scale:\n","                    weights.append(m[layer.name+'.weight'].data.numpy()) \n","                if layer.center:\n","                    weights.append(m[layer.name+'.bias'].data.numpy()) \n","                weights.append(m[layer.name+'.running_mean'].data.numpy()) \n","                weights.append(m[layer.name+'.running_var'].data.numpy()) \n","                layer.set_weights(weights)\n","            \n","            elif isinstance(layer, Dense):\n","                print(layer.name)\n","                weights = []\n","                weights.append(m[layer.name+'.weight'].t().data.numpy())\n","                if layer.use_bias:\n","                    weights.append(m[layer.name+'.bias'].data.numpy())\n","                layer.set_weights(weights)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bri5TJUj1d8h"},"source":["from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import Input,Add,Conv2D, Activation,BatchNormalization,ZeroPadding2D, MaxPooling2D, GlobalAveragePooling2D, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.models import load_model, Sequential\n","import tensorflow as tf\n","import tensorflow.keras.backend as K\n","from tensorflow.keras.layers import DepthwiseConv2D\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZL6AN5OYmwjq"},"source":["pth2keras(model,resnet50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h964mn7SulQq"},"source":["resnet50.save_weights('/content/drive/MyDrive/종합설계/myslowfast/pre_trained/rersnet50_places365.weights.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KrY1b2XV5ixj"},"source":["resnet50.save('/content/drive/MyDrive/종합설계/myslowfast/pre_trained/rersnet50_places365.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hVI4pOKQ19Dl"},"source":["resnet50.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T3Bk-5P45Lhp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606402019671,"user_tz":-540,"elapsed":48793,"user":{"displayName":"YOUNGJUN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXCkWtQqB5QSnRGkfHgYDCc_Ns7ntw7e80pQz6=s64","userId":"06692878673537715026"}},"outputId":"988a9d96-d051-4a1f-bead-9ee9a056f1a1"},"source":["from tensorflow.keras.models import load_model\n","model = load_model('/content/drive/MyDrive/종합설계/myslowfast/pre_trained/rersnet50_places365.h5')\n","model.summary()"],"execution_count":119,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"functional_18\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input (InputLayer)              [(None, 224, 224, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input[0][0]                      \n","__________________________________________________________________________________________________\n","conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","bn1 (BatchNormalization)        (None, 112, 112, 64) 256         conv1[0][0]                      \n","__________________________________________________________________________________________________\n","conv1_relu (Activation)         (None, 112, 112, 64) 0           bn1[0][0]                        \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","layer1.0.conv1 (Conv2D)         (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","layer1.0.bn1 (BatchNormalizatio (None, 56, 56, 64)   256         layer1.0.conv1[0][0]             \n","__________________________________________________________________________________________________\n","conv2_block0_1_relu (Activation (None, 56, 56, 64)   0           layer1.0.bn1[0][0]               \n","__________________________________________________________________________________________________\n","layer1.0.conv2 (Conv2D)         (None, 56, 56, 64)   36928       conv2_block0_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer1.0.bn2 (BatchNormalizatio (None, 56, 56, 64)   256         layer1.0.conv2[0][0]             \n","__________________________________________________________________________________________________\n","conv2_block0_2_relu (Activation (None, 56, 56, 64)   0           layer1.0.bn2[0][0]               \n","__________________________________________________________________________________________________\n","layer1.0.conv3 (Conv2D)         (None, 56, 56, 256)  16640       conv2_block0_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer1.0.downsample.0 (Conv2D)  (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","layer1.0.bn3 (BatchNormalizatio (None, 56, 56, 256)  1024        layer1.0.conv3[0][0]             \n","__________________________________________________________________________________________________\n","layer1.0.downsample.1 (BatchNor (None, 56, 56, 256)  1024        layer1.0.downsample.0[0][0]      \n","__________________________________________________________________________________________________\n","conv2_block0_add (Add)          (None, 56, 56, 256)  0           layer1.0.bn3[0][0]               \n","                                                                 layer1.0.downsample.1[0][0]      \n","__________________________________________________________________________________________________\n","conv2_block0_out (Activation)   (None, 56, 56, 256)  0           conv2_block0_add[0][0]           \n","__________________________________________________________________________________________________\n","layer1.1.conv1 (Conv2D)         (None, 56, 56, 64)   16448       conv2_block0_out[0][0]           \n","__________________________________________________________________________________________________\n","layer1.1.bn1 (BatchNormalizatio (None, 56, 56, 64)   256         layer1.1.conv1[0][0]             \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           layer1.1.bn1[0][0]               \n","__________________________________________________________________________________________________\n","layer1.1.conv2 (Conv2D)         (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer1.1.bn2 (BatchNormalizatio (None, 56, 56, 64)   256         layer1.1.conv2[0][0]             \n","__________________________________________________________________________________________________\n","conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           layer1.1.bn2[0][0]               \n","__________________________________________________________________________________________________\n","layer1.1.conv3 (Conv2D)         (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer1.1.bn3 (BatchNormalizatio (None, 56, 56, 256)  1024        layer1.1.conv3[0][0]             \n","__________________________________________________________________________________________________\n","conv2_block1_add (Add)          (None, 56, 56, 256)  0           layer1.1.bn3[0][0]               \n","                                                                 conv2_block0_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","layer1.2.conv1 (Conv2D)         (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","layer1.2.bn1 (BatchNormalizatio (None, 56, 56, 64)   256         layer1.2.conv1[0][0]             \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           layer1.2.bn1[0][0]               \n","__________________________________________________________________________________________________\n","layer1.2.conv2 (Conv2D)         (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer1.2.bn2 (BatchNormalizatio (None, 56, 56, 64)   256         layer1.2.conv2[0][0]             \n","__________________________________________________________________________________________________\n","conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           layer1.2.bn2[0][0]               \n","__________________________________________________________________________________________________\n","layer1.2.conv3 (Conv2D)         (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer1.2.bn3 (BatchNormalizatio (None, 56, 56, 256)  1024        layer1.2.conv3[0][0]             \n","__________________________________________________________________________________________________\n","conv2_block2_add (Add)          (None, 56, 56, 256)  0           layer1.2.bn3[0][0]               \n","                                                                 conv2_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","layer2.0.conv1 (Conv2D)         (None, 28, 28, 128)  32896       conv2_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","layer2.0.bn1 (BatchNormalizatio (None, 28, 28, 128)  512         layer2.0.conv1[0][0]             \n","__________________________________________________________________________________________________\n","conv3_block0_1_relu (Activation (None, 28, 28, 128)  0           layer2.0.bn1[0][0]               \n","__________________________________________________________________________________________________\n","layer2.0.conv2 (Conv2D)         (None, 28, 28, 128)  147584      conv3_block0_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer2.0.bn2 (BatchNormalizatio (None, 28, 28, 128)  512         layer2.0.conv2[0][0]             \n","__________________________________________________________________________________________________\n","conv3_block0_2_relu (Activation (None, 28, 28, 128)  0           layer2.0.bn2[0][0]               \n","__________________________________________________________________________________________________\n","layer2.0.conv3 (Conv2D)         (None, 28, 28, 512)  66048       conv3_block0_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer2.0.downsample.0 (Conv2D)  (None, 28, 28, 512)  131584      conv2_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","layer2.0.bn3 (BatchNormalizatio (None, 28, 28, 512)  2048        layer2.0.conv3[0][0]             \n","__________________________________________________________________________________________________\n","layer2.0.downsample.1 (BatchNor (None, 28, 28, 512)  2048        layer2.0.downsample.0[0][0]      \n","__________________________________________________________________________________________________\n","conv3_block0_add (Add)          (None, 28, 28, 512)  0           layer2.0.bn3[0][0]               \n","                                                                 layer2.0.downsample.1[0][0]      \n","__________________________________________________________________________________________________\n","conv3_block0_out (Activation)   (None, 28, 28, 512)  0           conv3_block0_add[0][0]           \n","__________________________________________________________________________________________________\n","layer2.1.conv1 (Conv2D)         (None, 28, 28, 128)  65664       conv3_block0_out[0][0]           \n","__________________________________________________________________________________________________\n","layer2.1.bn1 (BatchNormalizatio (None, 28, 28, 128)  512         layer2.1.conv1[0][0]             \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           layer2.1.bn1[0][0]               \n","__________________________________________________________________________________________________\n","layer2.1.conv2 (Conv2D)         (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer2.1.bn2 (BatchNormalizatio (None, 28, 28, 128)  512         layer2.1.conv2[0][0]             \n","__________________________________________________________________________________________________\n","conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           layer2.1.bn2[0][0]               \n","__________________________________________________________________________________________________\n","layer2.1.conv3 (Conv2D)         (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer2.1.bn3 (BatchNormalizatio (None, 28, 28, 512)  2048        layer2.1.conv3[0][0]             \n","__________________________________________________________________________________________________\n","conv3_block1_add (Add)          (None, 28, 28, 512)  0           layer2.1.bn3[0][0]               \n","                                                                 conv3_block0_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","layer2.2.conv1 (Conv2D)         (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","layer2.2.bn1 (BatchNormalizatio (None, 28, 28, 128)  512         layer2.2.conv1[0][0]             \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           layer2.2.bn1[0][0]               \n","__________________________________________________________________________________________________\n","layer2.2.conv2 (Conv2D)         (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer2.2.bn2 (BatchNormalizatio (None, 28, 28, 128)  512         layer2.2.conv2[0][0]             \n","__________________________________________________________________________________________________\n","conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           layer2.2.bn2[0][0]               \n","__________________________________________________________________________________________________\n","layer2.2.conv3 (Conv2D)         (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer2.2.bn3 (BatchNormalizatio (None, 28, 28, 512)  2048        layer2.2.conv3[0][0]             \n","__________________________________________________________________________________________________\n","conv3_block2_add (Add)          (None, 28, 28, 512)  0           layer2.2.bn3[0][0]               \n","                                                                 conv3_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","layer2.3.conv1 (Conv2D)         (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","layer2.3.bn1 (BatchNormalizatio (None, 28, 28, 128)  512         layer2.3.conv1[0][0]             \n","__________________________________________________________________________________________________\n","conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           layer2.3.bn1[0][0]               \n","__________________________________________________________________________________________________\n","layer2.3.conv2 (Conv2D)         (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer2.3.bn2 (BatchNormalizatio (None, 28, 28, 128)  512         layer2.3.conv2[0][0]             \n","__________________________________________________________________________________________________\n","conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           layer2.3.bn2[0][0]               \n","__________________________________________________________________________________________________\n","layer2.3.conv3 (Conv2D)         (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer2.3.bn3 (BatchNormalizatio (None, 28, 28, 512)  2048        layer2.3.conv3[0][0]             \n","__________________________________________________________________________________________________\n","conv3_block3_add (Add)          (None, 28, 28, 512)  0           layer2.3.bn3[0][0]               \n","                                                                 conv3_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","layer3.0.conv1 (Conv2D)         (None, 14, 14, 256)  131328      conv3_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","layer3.0.bn1 (BatchNormalizatio (None, 14, 14, 256)  1024        layer3.0.conv1[0][0]             \n","__________________________________________________________________________________________________\n","conv4_block0_1_relu (Activation (None, 14, 14, 256)  0           layer3.0.bn1[0][0]               \n","__________________________________________________________________________________________________\n","layer3.0.conv2 (Conv2D)         (None, 14, 14, 256)  590080      conv4_block0_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer3.0.bn2 (BatchNormalizatio (None, 14, 14, 256)  1024        layer3.0.conv2[0][0]             \n","__________________________________________________________________________________________________\n","conv4_block0_2_relu (Activation (None, 14, 14, 256)  0           layer3.0.bn2[0][0]               \n","__________________________________________________________________________________________________\n","layer3.0.conv3 (Conv2D)         (None, 14, 14, 1024) 263168      conv4_block0_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer3.0.downsample.0 (Conv2D)  (None, 14, 14, 1024) 525312      conv3_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","layer3.0.bn3 (BatchNormalizatio (None, 14, 14, 1024) 4096        layer3.0.conv3[0][0]             \n","__________________________________________________________________________________________________\n","layer3.0.downsample.1 (BatchNor (None, 14, 14, 1024) 4096        layer3.0.downsample.0[0][0]      \n","__________________________________________________________________________________________________\n","conv4_block0_add (Add)          (None, 14, 14, 1024) 0           layer3.0.bn3[0][0]               \n","                                                                 layer3.0.downsample.1[0][0]      \n","__________________________________________________________________________________________________\n","conv4_block0_out (Activation)   (None, 14, 14, 1024) 0           conv4_block0_add[0][0]           \n","__________________________________________________________________________________________________\n","layer3.1.conv1 (Conv2D)         (None, 14, 14, 256)  262400      conv4_block0_out[0][0]           \n","__________________________________________________________________________________________________\n","layer3.1.bn1 (BatchNormalizatio (None, 14, 14, 256)  1024        layer3.1.conv1[0][0]             \n","__________________________________________________________________________________________________\n","conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           layer3.1.bn1[0][0]               \n","__________________________________________________________________________________________________\n","layer3.1.conv2 (Conv2D)         (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer3.1.bn2 (BatchNormalizatio (None, 14, 14, 256)  1024        layer3.1.conv2[0][0]             \n","__________________________________________________________________________________________________\n","conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           layer3.1.bn2[0][0]               \n","__________________________________________________________________________________________________\n","layer3.1.conv3 (Conv2D)         (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer3.1.bn3 (BatchNormalizatio (None, 14, 14, 1024) 4096        layer3.1.conv3[0][0]             \n","__________________________________________________________________________________________________\n","conv4_block1_add (Add)          (None, 14, 14, 1024) 0           layer3.1.bn3[0][0]               \n","                                                                 conv4_block0_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","layer3.2.conv1 (Conv2D)         (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","layer3.2.bn1 (BatchNormalizatio (None, 14, 14, 256)  1024        layer3.2.conv1[0][0]             \n","__________________________________________________________________________________________________\n","conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           layer3.2.bn1[0][0]               \n","__________________________________________________________________________________________________\n","layer3.2.conv2 (Conv2D)         (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer3.2.bn2 (BatchNormalizatio (None, 14, 14, 256)  1024        layer3.2.conv2[0][0]             \n","__________________________________________________________________________________________________\n","conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           layer3.2.bn2[0][0]               \n","__________________________________________________________________________________________________\n","layer3.2.conv3 (Conv2D)         (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer3.2.bn3 (BatchNormalizatio (None, 14, 14, 1024) 4096        layer3.2.conv3[0][0]             \n","__________________________________________________________________________________________________\n","conv4_block2_add (Add)          (None, 14, 14, 1024) 0           layer3.2.bn3[0][0]               \n","                                                                 conv4_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","layer3.3.conv1 (Conv2D)         (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","layer3.3.bn1 (BatchNormalizatio (None, 14, 14, 256)  1024        layer3.3.conv1[0][0]             \n","__________________________________________________________________________________________________\n","conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           layer3.3.bn1[0][0]               \n","__________________________________________________________________________________________________\n","layer3.3.conv2 (Conv2D)         (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer3.3.bn2 (BatchNormalizatio (None, 14, 14, 256)  1024        layer3.3.conv2[0][0]             \n","__________________________________________________________________________________________________\n","conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           layer3.3.bn2[0][0]               \n","__________________________________________________________________________________________________\n","layer3.3.conv3 (Conv2D)         (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer3.3.bn3 (BatchNormalizatio (None, 14, 14, 1024) 4096        layer3.3.conv3[0][0]             \n","__________________________________________________________________________________________________\n","conv4_block3_add (Add)          (None, 14, 14, 1024) 0           layer3.3.bn3[0][0]               \n","                                                                 conv4_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","layer3.4.conv1 (Conv2D)         (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","layer3.4.bn1 (BatchNormalizatio (None, 14, 14, 256)  1024        layer3.4.conv1[0][0]             \n","__________________________________________________________________________________________________\n","conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           layer3.4.bn1[0][0]               \n","__________________________________________________________________________________________________\n","layer3.4.conv2 (Conv2D)         (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer3.4.bn2 (BatchNormalizatio (None, 14, 14, 256)  1024        layer3.4.conv2[0][0]             \n","__________________________________________________________________________________________________\n","conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           layer3.4.bn2[0][0]               \n","__________________________________________________________________________________________________\n","layer3.4.conv3 (Conv2D)         (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer3.4.bn3 (BatchNormalizatio (None, 14, 14, 1024) 4096        layer3.4.conv3[0][0]             \n","__________________________________________________________________________________________________\n","conv4_block4_add (Add)          (None, 14, 14, 1024) 0           layer3.4.bn3[0][0]               \n","                                                                 conv4_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","layer3.5.conv1 (Conv2D)         (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","layer3.5.bn1 (BatchNormalizatio (None, 14, 14, 256)  1024        layer3.5.conv1[0][0]             \n","__________________________________________________________________________________________________\n","conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           layer3.5.bn1[0][0]               \n","__________________________________________________________________________________________________\n","layer3.5.conv2 (Conv2D)         (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer3.5.bn2 (BatchNormalizatio (None, 14, 14, 256)  1024        layer3.5.conv2[0][0]             \n","__________________________________________________________________________________________________\n","conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           layer3.5.bn2[0][0]               \n","__________________________________________________________________________________________________\n","layer3.5.conv3 (Conv2D)         (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer3.5.bn3 (BatchNormalizatio (None, 14, 14, 1024) 4096        layer3.5.conv3[0][0]             \n","__________________________________________________________________________________________________\n","conv4_block5_add (Add)          (None, 14, 14, 1024) 0           layer3.5.bn3[0][0]               \n","                                                                 conv4_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n","__________________________________________________________________________________________________\n","layer4.0.conv1 (Conv2D)         (None, 7, 7, 512)    524800      conv4_block5_out[0][0]           \n","__________________________________________________________________________________________________\n","layer4.0.bn1 (BatchNormalizatio (None, 7, 7, 512)    2048        layer4.0.conv1[0][0]             \n","__________________________________________________________________________________________________\n","conv5_block0_1_relu (Activation (None, 7, 7, 512)    0           layer4.0.bn1[0][0]               \n","__________________________________________________________________________________________________\n","layer4.0.conv2 (Conv2D)         (None, 7, 7, 512)    2359808     conv5_block0_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer4.0.bn2 (BatchNormalizatio (None, 7, 7, 512)    2048        layer4.0.conv2[0][0]             \n","__________________________________________________________________________________________________\n","conv5_block0_2_relu (Activation (None, 7, 7, 512)    0           layer4.0.bn2[0][0]               \n","__________________________________________________________________________________________________\n","layer4.0.conv3 (Conv2D)         (None, 7, 7, 2048)   1050624     conv5_block0_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer4.0.downsample.0 (Conv2D)  (None, 7, 7, 2048)   2099200     conv4_block5_out[0][0]           \n","__________________________________________________________________________________________________\n","layer4.0.bn3 (BatchNormalizatio (None, 7, 7, 2048)   8192        layer4.0.conv3[0][0]             \n","__________________________________________________________________________________________________\n","layer4.0.downsample.1 (BatchNor (None, 7, 7, 2048)   8192        layer4.0.downsample.0[0][0]      \n","__________________________________________________________________________________________________\n","conv5_block0_add (Add)          (None, 7, 7, 2048)   0           layer4.0.bn3[0][0]               \n","                                                                 layer4.0.downsample.1[0][0]      \n","__________________________________________________________________________________________________\n","conv5_block0_out (Activation)   (None, 7, 7, 2048)   0           conv5_block0_add[0][0]           \n","__________________________________________________________________________________________________\n","layer4.1.conv1 (Conv2D)         (None, 7, 7, 512)    1049088     conv5_block0_out[0][0]           \n","__________________________________________________________________________________________________\n","layer4.1.bn1 (BatchNormalizatio (None, 7, 7, 512)    2048        layer4.1.conv1[0][0]             \n","__________________________________________________________________________________________________\n","conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           layer4.1.bn1[0][0]               \n","__________________________________________________________________________________________________\n","layer4.1.conv2 (Conv2D)         (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer4.1.bn2 (BatchNormalizatio (None, 7, 7, 512)    2048        layer4.1.conv2[0][0]             \n","__________________________________________________________________________________________________\n","conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           layer4.1.bn2[0][0]               \n","__________________________________________________________________________________________________\n","layer4.1.conv3 (Conv2D)         (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer4.1.bn3 (BatchNormalizatio (None, 7, 7, 2048)   8192        layer4.1.conv3[0][0]             \n","__________________________________________________________________________________________________\n","conv5_block1_add (Add)          (None, 7, 7, 2048)   0           layer4.1.bn3[0][0]               \n","                                                                 conv5_block0_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","layer4.2.conv1 (Conv2D)         (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","layer4.2.bn1 (BatchNormalizatio (None, 7, 7, 512)    2048        layer4.2.conv1[0][0]             \n","__________________________________________________________________________________________________\n","conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           layer4.2.bn1[0][0]               \n","__________________________________________________________________________________________________\n","layer4.2.conv2 (Conv2D)         (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer4.2.bn2 (BatchNormalizatio (None, 7, 7, 512)    2048        layer4.2.conv2[0][0]             \n","__________________________________________________________________________________________________\n","conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           layer4.2.bn2[0][0]               \n","__________________________________________________________________________________________________\n","layer4.2.conv3 (Conv2D)         (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","layer4.2.bn3 (BatchNormalizatio (None, 7, 7, 2048)   8192        layer4.2.conv3[0][0]             \n","__________________________________________________________________________________________________\n","conv5_block2_add (Add)          (None, 7, 7, 2048)   0           layer4.2.bn3[0][0]               \n","                                                                 conv5_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","global_average_pooling2d_8 (Glo (None, 2048)         0           conv5_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","fc (Dense)                      (None, 365)          747885      global_average_pooling2d_8[0][0] \n","==================================================================================================\n","Total params: 24,335,597\n","Trainable params: 24,282,477\n","Non-trainable params: 53,120\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cs3xjQGmBMOj","executionInfo":{"status":"ok","timestamp":1606402306984,"user_tz":-540,"elapsed":639,"user":{"displayName":"YOUNGJUN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXCkWtQqB5QSnRGkfHgYDCc_Ns7ntw7e80pQz6=s64","userId":"06692878673537715026"}},"outputId":"9cf1e958-a34d-48b4-8f72-0ff57bc4ff3a"},"source":["model.bn1.weight"],"execution_count":121,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([1.8909e-01, 2.4901e-01, 1.9841e-01, 1.8410e-01, 2.1704e-01, 2.1509e-01,\n","        4.4340e-01, 2.0513e-01, 2.5493e-01, 2.9115e-01, 1.7579e-01, 2.9227e-01,\n","        2.0049e-01, 1.8420e-01, 2.7392e-01, 2.3525e-01, 1.4871e-01, 1.3668e-02,\n","        2.0359e-01, 2.2271e-01, 1.3577e-01, 2.2679e-01, 2.1140e-01, 2.5941e-01,\n","        2.3493e-01, 1.3843e-01, 3.7948e-01, 2.8138e-01, 2.9369e-01, 1.9642e-01,\n","        2.7615e-01, 3.6064e-04, 2.1563e-01, 2.8072e-14, 2.2207e-01, 3.0018e-01,\n","        2.2407e-01, 3.2249e-01, 2.5590e-01, 2.2630e-01, 2.9592e-14, 3.0339e-01,\n","        3.4273e-01, 3.1103e-01, 2.0199e-01, 2.0363e-01, 2.2530e-01, 2.0963e-14,\n","        2.0102e-01, 2.8391e-01, 2.0292e-01, 3.2868e-01, 2.0753e-01, 3.3879e-01,\n","        4.0337e-01, 2.3034e-01, 2.6471e-01, 2.2812e-14, 1.7924e-01, 2.4133e-01,\n","        4.1546e-01, 2.0727e-01, 3.4147e-14, 1.9111e-01], requires_grad=True)"]},"metadata":{"tags":[]},"execution_count":121}]},{"cell_type":"code","metadata":{"id":"Fv5I_ow9CfD1","executionInfo":{"status":"ok","timestamp":1606402328763,"user_tz":-540,"elapsed":945,"user":{"displayName":"YOUNGJUN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXCkWtQqB5QSnRGkfHgYDCc_Ns7ntw7e80pQz6=s64","userId":"06692878673537715026"}},"outputId":"ff1a10b5-bf1b-44ab-ed71-f779eb1de5f3","colab":{"base_uri":"https://localhost:8080/"}},"source":["resnet50.layers[3].weights"],"execution_count":124,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<tf.Variable 'bn1/gamma:0' shape=(64,) dtype=float32, numpy=\n"," array([1.8908732e-01, 2.4901241e-01, 1.9840589e-01, 1.8410338e-01,\n","        2.1704429e-01, 2.1508966e-01, 4.4340241e-01, 2.0512900e-01,\n","        2.5492764e-01, 2.9115415e-01, 1.7578697e-01, 2.9227176e-01,\n","        2.0048775e-01, 1.8419622e-01, 2.7392083e-01, 2.3524737e-01,\n","        1.4870973e-01, 1.3667652e-02, 2.0358528e-01, 2.2271213e-01,\n","        1.3576655e-01, 2.2678852e-01, 2.1139941e-01, 2.5941479e-01,\n","        2.3492940e-01, 1.3843332e-01, 3.7947831e-01, 2.8137761e-01,\n","        2.9368532e-01, 1.9641572e-01, 2.7614868e-01, 3.6064044e-04,\n","        2.1562637e-01, 2.8071770e-14, 2.2206840e-01, 3.0017763e-01,\n","        2.2407429e-01, 3.2248896e-01, 2.5589982e-01, 2.2630025e-01,\n","        2.9592444e-14, 3.0339092e-01, 3.4272552e-01, 3.1103432e-01,\n","        2.0198752e-01, 2.0362729e-01, 2.2529826e-01, 2.0962502e-14,\n","        2.0102371e-01, 2.8391078e-01, 2.0292397e-01, 3.2867524e-01,\n","        2.0753351e-01, 3.3878627e-01, 4.0336683e-01, 2.3033774e-01,\n","        2.6470822e-01, 2.2811612e-14, 1.7924441e-01, 2.4132532e-01,\n","        4.1545898e-01, 2.0726657e-01, 3.4146642e-14, 1.9110915e-01],\n","       dtype=float32)>,\n"," <tf.Variable 'bn1/beta:0' shape=(64,) dtype=float32, numpy=\n"," array([ 1.82430401e-01,  1.98224872e-01,  2.11519986e-01,  1.76675677e-01,\n","         1.73289388e-01,  1.55620813e-01,  8.50711226e-01,  1.85329422e-01,\n","         4.67516243e-01,  3.84662539e-01, -8.87152702e-02, -1.29798234e-01,\n","         3.04852605e-01,  2.03066930e-01,  1.56339958e-01,  4.25159991e-01,\n","         1.95191756e-01,  2.12668395e-03, -3.04607362e-01,  4.77025568e-01,\n","        -5.16093783e-02,  4.71294731e-01,  1.99529976e-01,  8.76916498e-02,\n","         2.38055632e-01, -1.23752415e-01, -2.90189058e-01,  3.76423150e-01,\n","         2.20126212e-01,  1.88528746e-01,  4.68482554e-01, -8.59293679e-04,\n","         1.86193958e-01, -8.19273238e-14,  4.48825032e-01,  9.60908756e-02,\n","         1.90673247e-01, -3.93760771e-01,  1.67794600e-01,  5.68918362e-02,\n","        -8.20996577e-14,  1.34088695e-01, -3.49061131e-01,  1.28914729e-01,\n","         6.20573401e-01,  1.47281483e-01,  2.20822379e-01, -6.05706078e-14,\n","         5.19537508e-01, -2.44772390e-01,  2.41318733e-01,  6.89806581e-01,\n","         1.88196614e-01,  8.02535832e-01, -4.26568925e-01, -2.54605383e-01,\n","         2.18198940e-01, -7.56333337e-14, -1.75026536e-01,  3.60433400e-01,\n","        -3.06231290e-01,  1.86491132e-01, -9.74457060e-14,  2.13553086e-01],\n","       dtype=float32)>,\n"," <tf.Variable 'bn1/moving_mean:0' shape=(64,) dtype=float32, numpy=\n"," array([ 1.1263478e-02,  2.5034493e-02, -5.7188910e-03, -2.5882800e-03,\n","        -5.0856075e-03, -4.0196334e-03, -3.7079147e-01,  3.3635562e-03,\n","         7.7774704e-02, -2.2077292e-01, -9.7377375e-02,  1.0348915e-01,\n","         1.5374905e-01,  9.6793771e-03, -3.3449970e-02,  4.0706687e-02,\n","        -4.9865082e-02, -1.1349205e-03, -6.5507613e-02,  1.1371644e-01,\n","        -7.3851816e-02, -1.8302042e-03,  1.3868597e-02, -4.5200367e-03,\n","         1.6228145e-03, -1.6347826e-02,  1.2352961e-02, -7.4446052e-02,\n","        -5.2846011e-02, -1.0466067e-03,  8.7545685e-02,  4.3767691e-04,\n","         1.1746602e-02, -1.5333614e-13, -6.6094063e-02,  5.6803934e-03,\n","        -1.8134937e-02, -1.6468754e-01,  3.0398777e-01,  8.2448550e-02,\n","        -5.7175380e-13,  1.0289551e-02, -1.2640482e-01,  2.5172720e-02,\n","         2.5307900e-01, -4.5964858e-03, -3.2150548e-02, -2.0027347e-13,\n","        -1.8030089e-01,  2.7275227e-02, -1.3301875e-03,  1.7557347e-01,\n","        -1.1384257e-03,  2.2363967e-01,  1.9450857e-01, -1.8688391e-01,\n","        -5.1451489e-02, -1.3033551e-13, -3.4036160e-02, -2.6066723e-01,\n","         1.6518274e-01, -3.9873016e-03, -1.5806864e-13,  2.3058925e-02],\n","       dtype=float32)>,\n"," <tf.Variable 'bn1/moving_variance:0' shape=(64,) dtype=float32, numpy=\n"," array([6.2889284e-01, 2.0737166e+00, 3.0173436e-01, 4.7818711e-01,\n","        7.2335011e-01, 6.2975717e-01, 2.4180489e+01, 7.7298182e-01,\n","        2.2122068e+00, 6.9346642e+00, 6.9717014e-01, 2.4893341e+00,\n","        2.6686828e+00, 3.5385668e-01, 3.1099265e+00, 3.3837004e+00,\n","        5.7440656e-01, 7.7261273e-03, 1.0340465e+00, 2.3154771e+00,\n","        4.3566778e-01, 2.5561976e+00, 4.8641858e-01, 3.0024822e+00,\n","        5.8620620e-01, 5.2021527e-01, 5.9474092e+00, 2.7790279e+00,\n","        3.1724536e+00, 2.2295311e-01, 3.0096571e+00, 2.0964042e-05,\n","        8.0565608e-01, 8.8372356e-24, 2.5833976e+00, 6.3129420e+00,\n","        8.0422813e-01, 3.0673587e+00, 7.3947172e+00, 1.7318211e+00,\n","        4.7246956e-23, 6.2267008e+00, 2.7890248e+00, 5.5840955e+00,\n","        4.2000194e+00, 7.5177497e-01, 1.4599160e+00, 6.6260585e-24,\n","        6.1175480e+00, 2.2837710e+00, 1.9660032e-01, 6.4194336e+00,\n","        4.5553157e-01, 9.4333572e+00, 4.7639127e+00, 2.2315707e+00,\n","        2.5400105e+00, 3.6901438e-24, 7.8682232e-01, 4.6909943e+00,\n","        4.9406319e+00, 8.1000423e-01, 4.7207129e-24, 6.4305365e-01],\n","       dtype=float32)>]"]},"metadata":{"tags":[]},"execution_count":124}]},{"cell_type":"code","metadata":{"id":"82oZ3B1DChzZ"},"source":[""],"execution_count":null,"outputs":[]}]}