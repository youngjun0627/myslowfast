{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dataset.ipynb","provenance":[],"private_outputs":true,"mount_file_id":"1poCEnuXxHI3RBaOu-bY4ru0pmqCVT3To","authorship_tag":"ABX9TyO/rWp3jpV7jeBWjjdSGrjR"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"GrH71KdF3AF9"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iJ3YsGvk3OX1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vTKX-ZaT3Woa"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_PswNiwX3beY"},"source":["import random\n","import math\n","import copy\n","import numpy as np\n","from tensorflow.keras.utils import Sequence\n","from dataset.spatial_transforms import RandomCrop, Scale, RandomScale, RandomHorizontalFlip, CenterCrop, Compose, Normalize\n","from dataset.tempora_transforms import TemporalRandomCrop, TemporalCenterCrop\n","#from dataset.utils import load_value_file, load_clip_video"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L9o6n27k4B67"},"source":["class DataGenerator(Sequence):\n","  def __init__(self, video_path, file_path, name_path, \n","             mode, batch_size, num_classes, shuffle, \n","             short_size = (256,320), crop_size = 224, clip_len=64, n_samples_for_each_video = 1):\n","    \n","    if mode == 'train':\n","      self.spatial_transforms = Compose([\n","                                         RandomScale(short_side),\n","                                         RandomCrop(crop_size),\n","                                         RandomHorizontalFlip(),\n","                                         Normalize()\n","      ])\n","      self.temporal_transforms = TemporalRandomCrop(clip_len)\n","\n","    elif mode == 'val':\n","      self.spatial_transforms = Compose([\n","                                         Scale(short_side),\n","                                         CenterCrop(crop_size),\n","                                         Normalize()\n","      ])\n","      self.temporal_transforms = TemporalRandomCrop(clip_len)\n","\n","    else:\n","      raise ValueError(\"invalid mode\")\n","\n","    self.dataset = self.makedataset(n_samples_for_each_video, clip_len)\n","    if self.shuffle:\n","      random.shuffle(self.dataset)\n","\n","\n","    def __len__(self):\n","      return math.ceil(len(self.video_files)/self.batch_size)\n","\n","    def __getitem__(self, index):\n","      batch_dataset = self.dataset[index*self.batch_size:(index+1)*self.batch_size]\n","      video_data, label_data = self.data_generator(batch_dataset)\n","      return video_data, label_data\n","\n","    def on_epoch_end(self):\n","      if self.shuffle:\n","        random.shuffle(self.dataset)\n","\n","  def makedataset(self, n_samples_for_each_video, clip_len):\n","    dataset = []\n","    for i, video_file in enumrate(self.video_files):\n","      if i%100==0:\n","        print('dataset loading [ {0} / {1}]'.format(1, len*self.video_files))\n","      if not os.path.exists(video_files):\n","        print('{0} is not exist'.format(video_file))\n","        continue\n","\n","      n_frame_path = os.path.join(video_file, 'n_frames')\n","      n_frames = int(load_value_file(n_frame_path))\n","\n","      if n_frames<=0:\n","        continue\n","\n","      sample = {\n","          'video_path' : video_file,\n","          'label' : int(self.label_files[i])\n","      }\n","      if n_samples_for_each_video==1:\n","        sample['frame_indices'] = list(range(1, n_frames+1))\n","      else:\n","        if n_samples_for_each_video>1:\n","          step = max(1, math.ceil((n_frames-1-clip_len)/ (n_samples_for_each_video-1)))\n","        else:\n","          step = clip_len\n","\n","        for j in range(1, n_frames, step):\n","          sample_j = copy.deepcopy(sample)\n","          sample_j['frame_indices'] = list(range(j, min(n_frames + 1, j + clip_len)))\n","          dataset.append(sample_j)\n","    \n","    return dataset\n","\n","    def data_generator(self, batch_dataset):\n","      video_data = []\n","      label_data = []\n","      for data in batch_dataset:    #batch_dataset은 sample의 집합체\n","        path = data['video_path']\n","        frame_indeices = data['frame_indices']\n","        if self.temporal_transforms is not None:\n","          frame_indices = self.temporal_transforms(frame_indices)\n","        \n","        clip = load_clip_video(path, frame_indeices)\n","\n","        if self.spatial_transforms is not None:\n","          self.spatial_transforms.randomize_parameters()\n","          clip = [self.spatial_transforms(img) for img in clip]\n","\n","        clip = np.stack(clip,0)\n","        video_data.append(clip)\n","        label_data.append(data['label'])\n","      video_data = np.array(video_data)\n","      label_data = np.eye(self.num_classes)[label_data]\n","\n","      return video_data, label_data\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WiLmqfQQ4Y7S"},"source":["n_frames = 128\n","clip_len=64\n","n_samples_for_each_video=3\n","step = max(1, math.ceil((n_frames-1-clip_len)/ (n_samples_for_each_video-1)))\n","print(step)\n","dataset = []\n","video_files = os.listdir('/content/drive/MyDrive/종합설계/movies/NonViolence')\n","for i, video_file in enumerate(video_files):\n","  sample = {\n","                  'video_path':video_file,\n","                  'label': 'Nonviolence'\n","              }\n","  for j in range(1, n_frames, step):\n","    sample_j = copy.deepcopy(sample)\n","    sample_j['frame_indices'] = list(range(j, min(n_frames+1, j+clip_len)))\n","    dataset.append(sample_j)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VymPWf4G-SM3"},"source":["]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HqWvYNRj_jJK"},"source":[""],"execution_count":null,"outputs":[]}]}